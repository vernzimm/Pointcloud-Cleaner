Training Data = Large Pointcloud chunks with Good and Bad points tagged.

First section - process patches of the pointcloud and decide whether or not that patch contains a bad point. This is a rough run to avoid checking 100% points. Patches overlap somewhat (use octree?). This CNN is similar to image recognition. Don't actually determine what points are bad, just do a scan of that group and decide if it contains 1 or more bad points. Return patch spacial coords and T/F contains bad points.

Second section - Only those patches that contain bad points are processed point-by-point. Each point in a bad patch is grouped with a certain quantity of nearest neighbors, regardless if they actually reside in the original patch (avoids the problem if bad point is on a border.) The patches sub-set the original data in first section, then second section creates its own patches using nearest neighbor. Each second section patch is split into "point" and "neighbors", and the result of bad point = T/F is applied to "point" only. Immediately exclude that point from further consideration? Maybe the "neighbors" should be classified as (good,bad,unknwn). If a known "bad" point is included as a neighbor, it may be relevant to the determination of "point" (they are very similar would weigh more toward "point" = "bad").